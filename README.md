---
description: A slide for the paper that given below
---

# Report

## Sequence to Sequence Learning with Neural Networks

### Introduction

* **Background-info:** Given a large labeled training sets,Deep Neural NetWorks\(DNNs\) can not be used to map sequences to sequences\(STS\).
  * _The limitation of DNNs_: It can **only** be applied to problems whose inputs and targets can be sensibly encoded with vectors of fixed dimension.
* **Objective**: A general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure.
* **Method**: Long Short-Term Memory\(LSTM\) can solve general the STS problems.The advantages of LSTM is that it learns to map an input sentence of variable length into a fixed-dimensional vector representation.

### Model Structure

* Two different LSTMs:
  * 

